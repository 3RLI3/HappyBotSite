<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README_HappyBot</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<h1
id="happybot-a-multimodal-generative-ai-telegram-assistant">HappyBot: A
Multimodal Generative AI Telegram Assistant</h1>
<p>HappyBot is a Telegram bot designed to provide emotional support,
wellness check-ins, and intelligent conversations using a Generative AI
backend (SEA-LION LLM). The bot integrates a Mini App (Telegram Web
App), handles both text and voice input, and is deployed using webhook
mode on Render.com.</p>
<hr />
<h2 id="features">üìå Features</h2>
<ul>
<li>ü§ñ LLM-powered responses (via SEA-LION API)</li>
<li>üß† LangChain context-aware prompt formatting</li>
<li>üéôÔ∏è Voice message transcription and voice reply (Sphinx + gTTS)</li>
<li>üìÜ Weekly wellbeing check-in with Telegram polls</li>
<li>üì≤ Telegram Mini App for setting custom alerts (HTML/CSS/JS)</li>
<li>‚òÅÔ∏è Hosted on Render using webhook deployment</li>
<li>üîÅ Redis (or fallback in-memory) for context and conversation
memory</li>
</ul>
<hr />
<h2 id="tech-stack">‚öôÔ∏è Tech Stack</h2>
<table>
<thead>
<tr>
<th>Component</th>
<th>Tech Used</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backend</td>
<td>Python, Flask (for webhook), Telegram Bot API</td>
</tr>
<tr>
<td>AI Model</td>
<td>SEA-LION (via HTTP API)</td>
</tr>
<tr>
<td>LLM Prompting</td>
<td>LangChain + Custom Templates</td>
</tr>
<tr>
<td>Voice Input</td>
<td>speech_recognition (Sphinx) + pydub</td>
</tr>
<tr>
<td>TTS Response</td>
<td>gTTS (Google Text-to-Speech)</td>
</tr>
<tr>
<td>Mini App</td>
<td>Telegram WebApp + static HTML/JS</td>
</tr>
<tr>
<td>Hosting</td>
<td>Render.com (Webhook mode)</td>
</tr>
<tr>
<td>Storage</td>
<td>Redis or in-memory fallback</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="directory-structure">üìÅ Directory Structure</h2>
<pre><code>app/
‚îÇ
‚îú‚îÄ‚îÄ telegram_bot.py       # Main app entrypoint
‚îú‚îÄ‚îÄ session_db.py         # Redis/memory store for user sessions
‚îú‚îÄ‚îÄ langchain_prompts.py  # Prompt formatting using LangChain
‚îú‚îÄ‚îÄ sea_lion_api.py       # Wrapper around SEA-LION HTTP API
‚îú‚îÄ‚îÄ templates/            # MiniApp HTML templates (optional)
‚îú‚îÄ‚îÄ static/               # JS/CSS assets for Mini App
‚îî‚îÄ‚îÄ .env                  # Secrets and environment variables</code></pre>
<hr />
<h2 id="deployment-on-render">üöÄ Deployment on Render</h2>
<ol type="1">
<li>Set up a <strong>Python Web Service</strong> on Render.</li>
<li>Ensure <code>webhook_url</code> and <code>TELEGRAM_TOKEN</code> are
in your <code>.env</code>.</li>
<li>Use the following startup command:</li>
</ol>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> set_webhook.py <span class="kw">&amp;&amp;</span> <span class="ex">python</span> <span class="at">-m</span> app.telegram_bot</span></code></pre></div>
<ol start="4" type="1">
<li>Expose <code>/telegram</code> route for Telegram Webhook.</li>
<li>Add <code>uptimerobot.com</code> ping if you want to keep the bot
alive.</li>
</ol>
<hr />
<h2 id="voice-input">üîä Voice Input</h2>
<ul>
<li>Receives <code>.ogg</code> Telegram voice message</li>
<li>Converts to <code>.wav</code> using <code>pydub</code></li>
<li>Transcribes with <code>SpeechRecognition</code> (Sphinx)</li>
<li>Uses text to query LLM, sends both text and voice reply (via
<code>gTTS</code>)</li>
</ul>
<hr />
<h2 id="context-memory">üß† Context &amp; Memory</h2>
<ul>
<li><code>session_db.py</code> handles storing user context
(<code>context:{chat_id}</code>) and history
(<code>history:{chat_id}</code>)</li>
<li>Uses Redis if available, else falls back to in-memory Python
dict</li>
<li>History truncated to last 4 exchanges (configurable via
<code>MAX_HISTORY_LEN</code>)</li>
</ul>
<hr />
<h2 id="telegram-mini-app">üß© Telegram Mini App</h2>
<ul>
<li>A simple WebApp interface in
<code>static/miniapp/index.html</code></li>
<li>Users can submit alerts (POST to Flask API)</li>
<li>Button appears via <code>WebAppInfo</code> inside
<code>/start</code> reply</li>
</ul>
<hr />
<h2 id="testing-debugging-tips">üß™ Testing &amp; Debugging Tips</h2>
<ul>
<li>Test locally using <code>python -m app.telegram_bot</code></li>
<li>Use <code>logging.info(...)</code> to track handler activity</li>
<li>Always wrap LLM calls in <code>try/except</code> for graceful
failure</li>
<li>Redis not available? It will fallback to <code>_cache</code> in
memory</li>
</ul>
<hr />
<h2 id="contributing">ü§ù Contributing</h2>
<ul>
<li>Extend with more wellbeing tools (e.g., journaling, CBT cards)</li>
<li>Swap SEA-LION with local Ollama models if needed</li>
<li>Improve multilingual support for wider accessibility</li>
</ul>
<hr />
<h2 id="license">üìÑ License</h2>
<p>MIT License ‚Äì Use freely and improve for good üåç</p>
<hr />
<p>HappyBot is a capstone example of combining Generative AI, chat
interfaces, multimodal input, and cloud deployment to solve real human
needs.</p>
</body>
</html>
